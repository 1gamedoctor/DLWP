{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DLWP on Azure with Microsoft Azure Machine Learning service\n",
    "For a reference on getting started with the Microsoft Azure Machine Learning service, refer to the [Microsoft documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/).\n",
    "\n",
    "First, let's import the core AzureML Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create or import a workspace\n",
    "In this example, we assume a workspace already exists, but it is easy to create a workspace on-the-fly with `Workspace.create()`. Use environment variables to load sensitive information such as `subscription_id` and authentication passwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.get(\n",
    "    name='dlwp-ml-1',\n",
    "    subscription_id=os.environ.get('AZURE_SUBSCRIPTION_ID'),\n",
    "    resource_group='DLWP'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the compute cluster\n",
    "This code, adapted from the Microsoft documentation example, checks for existing compute resources in the workspace or creates them if they do not exist. We use GPU nodes, of which there are a few choices:\n",
    "- STANDARD_NC6: Tesla K80\n",
    "- STANDARD_NC6_v2: Tesla P100\n",
    "- STANDARD_NC6_v3: Tesla V100\n",
    "- STANDARD_ND6: Tesla P40\n",
    "- STANDARD_NV6: Tesla M60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target (dlwp-compute-1)\n"
     ]
    }
   ],
   "source": [
    "# Name of the cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"dlwp-compute-1\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 2)\n",
    "\n",
    "# Set a GPU VM type\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_NV6\")\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target (%s)' % compute_name)\n",
    "else:\n",
    "    print('creating a new compute target (%s)' % compute_name)\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy data to the compute cluster\n",
    "This optional step is needed if data hasn't yet been uploaded to a storage blob connected to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob dlwpml10633119839 azureml-blobstore-ba10431a-baca-4271-b9e8-283bd838c07e\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "# ds.upload(src_dir=data_folder, target_path='DLWP', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'dlwp'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a TensorFlow estimator\n",
    "Now we create an image for a TensorFlow estimator that will be used as the VM for the compute cluster. Azure creates a Docker image the first time this is run; in the future, it can re-use existing images to run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--root-directory': ds.path('DLWP').as_mount(),\n",
    "    '--predictor-file': 'cfs_1979-2010_hgt-thick_300-500-700_NH_T2.nc',\n",
    "    '--model-file': 'dlwp_tau-lstm',\n",
    "    '--log-directory': 'logs/tau-lstm',\n",
    "    '--temp-dir': '/mnt/tmp'\n",
    "}\n",
    "\n",
    "tf_est = TensorFlow(source_directory=os.path.join(os.getcwd(), os.pardir),\n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script=os.path.join(os.getcwd(), 'train_tf.py'),\n",
    "                    conda_packages=['scikit-learn', 'netCDF4', 'dask', 'xarray'],\n",
    "                    pip_packages=['keras'],\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>dlwp</td><td>dlwp_1553550932_94c28310</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/c31a4a22-148c-42a4-8c71-7426ed84587f/resourceGroups/DLWP/providers/Microsoft.MachineLearningServices/workspaces/dlwp-ml-1/experiments/dlwp/runs/dlwp_1553550932_94c28310\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: dlwp,\n",
       "Id: dlwp_1553550932_94c28310,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(config=tf_est)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
